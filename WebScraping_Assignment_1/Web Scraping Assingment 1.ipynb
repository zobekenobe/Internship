{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7f0ff80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "b867b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "url2 = 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc'\n",
    "url3 = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "url4 = 'https://meesho.com/bags-ladies/pl/p7vbp'\n",
    "url5a= 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "url5b = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "url5c= 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "url7 = 'https://coreyms.com/'\n",
    "url8 = 'https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIiLCJzaG93TWFwIjpmYWxzZX0seyJsYXQiOjEyLjkzMDc3MzUsImxvbiI6NzcuNTgzODMwMiwicGxhY2VJZCI6IkNoSUoyZGRsWjVnVnJqc1JoMUJPQWFmLW9ycyIsInBsYWNlTmFtZSI6IkpheWFuYWdhciIsInNob3dNYXAiOmZhbHNlfSx7ImxhdCI6MTIuOTc4MzY5MiwibG9uIjo3Ny42NDA4MzU2LCJwbGFjZUlkIjoiQ2hJSmtRTjNHS1FXcmpzUk5oQlFKcmhHRDdVIiwicGxhY2VOYW1lIjoiSW5kaXJhbmFnYXIiLCJzaG93TWFwIjpmYWxzZX1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "93f9b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1(url):\n",
    "    text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    soup = bs(text)\n",
    "    headers = soup.find_all('head')\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3e5c6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2(url):\n",
    "    '''Since the top 100 are split over the two pages, two page links are created'''\n",
    "    page1 = requests.get(url)\n",
    "    page2 = requests.get(url + '&start=51&ref_=adv_nxt')\n",
    "    movie_list = []\n",
    "    for _ in [page1, page2]:\n",
    "        soup = bs(_.content)\n",
    "        text = soup.find_all('h3', {'class':'lister-item-header'})\n",
    "        movie_list += [_.text.split('\\n')[1:4] for _ in text]\n",
    "    df = pd.DataFrame(movie_list, columns = ['Rank', 'Movie Name', 'Year'])\n",
    "    df.set_index('Rank', inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "47021cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3(url):\n",
    "    '''\n",
    "    Since the imdb site list the top 250 movies, the list is truncated to \n",
    "    the top 100 as required\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    text = soup.find_all('td', {'class':'titleColumn'})\n",
    "    rate = soup.find_all('td', {'class':'ratingColumn imdbRating'})\n",
    "    names  = [_.text.split('\\n')[1:4] for _ in text][0:100] \n",
    "    rating = [_.text.split('\\n')[1] for _ in rate][0:100]\n",
    "\n",
    "    df = pd.DataFrame(names, columns = ['Rank', 'Movie Name', 'Year'])\n",
    "    df.set_index('Rank', inplace = True)\n",
    "    df['rating'] = rating\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ade7a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question4(url):\n",
    "    page = requests.get(url)\n",
    "    text = soup(page.content)\n",
    "    name = soup.find_all('p', {'class':'Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS'})\n",
    "    price= soup.find_all('h5',{'class':'Text__StyledText-sc-oo0kvp-0 hiHdyy'})\n",
    "    disc = soup.find_all('span', {'class' : 'Text__StyledText-sc-oo0kvp-0 lnonyH'})\n",
    "    name = [_.text for _ in name]\n",
    "    price= [_.text for _ in price]\n",
    "    disc = [_.text for _ in disc]\n",
    "    # to accomodate for cases with no discount\n",
    "    p = re.compile('â‚¹0')\n",
    "    i = next(i for i in range(len(price)) if p.findall(price[i]))\n",
    "    disc.insert(i, '0% off')\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Price':price, 'Discount':disc})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "eace2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5a(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    team = soup.find_all('span', {'class':'u-hide-phablet'})\n",
    "    details = soup.find_all('td', {'class':'table-body__cell u-center-text'})\n",
    "    rating  = soup.find_all('td', {'class':'table-body__cell u-text-right rating'})\n",
    "\n",
    "    team = [_.text for _ in team][:10]\n",
    "    details = [_.text for _ in details]\n",
    "    rating  = [_.text for _ in rating]\n",
    "\n",
    "    match = [soup.find('td', {'class':'rankings-block__banner--matches'}).text]+details[0:18:2]\n",
    "    point = [soup.find('td', {'class':'rankings-block__banner--points'}).text] +details[1:18:2]\n",
    "    rating= [soup.find('td', {'class':'rankings-block__banner--rating u-text-right'}).text.split('\\n')[1].strip()] + rating[:9]\n",
    "    df = pd.DataFrame(data = {'Team':team, 'Matches':match, 'Points':point, 'Rating':rating}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "45c10204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5b(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "cdaafdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5c(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "fc676269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6a(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    team = soup.find_all('span', {'class':'u-hide-phablet'})\n",
    "    details = soup.find_all('td', {'class':'table-body__cell u-center-text'})\n",
    "    rating  = soup.find_all('td', {'class':'table-body__cell u-text-right rating'})\n",
    "\n",
    "    team = [_.text for _ in team][:10]\n",
    "    details = [_.text for _ in details]\n",
    "    rating  = [_.text for _ in rating]\n",
    "\n",
    "    match = [soup.find('td', {'class':'rankings-block__banner--matches'}).text]+details[0:18:2]\n",
    "    point = [soup.find('td', {'class':'rankings-block__banner--points'}).text] +details[1:18:2]\n",
    "    rating= [soup.find('td', {'class':'rankings-block__banner--rating u-text-right'}).text.split('\\n')[1].strip()] + rating[:9]\n",
    "    df = pd.DataFrame(data = {'Team':team, 'Matches':match, 'Points':point, 'Rating':rating}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "12b0c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6b(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "3906d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6c(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "32b1aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question7(url):\n",
    "    page= requests.get(url)\n",
    "    soup= bs(page.content)\n",
    "    title = soup.find_all('a', {'class':'entry-title-link'})\n",
    "    time  = soup.find_all('time', {'class':'entry-time'})\n",
    "    content = soup.find_all('div',{'class':'entry-content'})\n",
    "    link = soup.find_all('iframe', {'class':'youtube-player'})\n",
    "\n",
    "    title   = [_.text for _ in title]\n",
    "    time    = [_.text for _ in time]\n",
    "    content = [_.text.replace('\\n','').strip() for _ in content]\n",
    "    link    = [_['src'] for _ in link]\n",
    "    link.insert(4, 'No Link')\n",
    "    df = pd.DataFrame(data={'Title':title,'Date':time,'Content':content,'Youtube Link':link}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question8(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "68eff209",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ZOBEKE~1\\AppData\\Local\\Temp/ipykernel_4968/4214092137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m df = pd.DataFrame(data = {'House Title':house[0], 'Location':place,\n\u001b[1;32m---> 17\u001b[1;33m                           'EMI':emi, 'Price':price})\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "page = requests.get(url8)\n",
    "soup = bs(page.content)\n",
    "name = soup.find_all('span',{'class':'overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full'})\n",
    "price= soup.find_all('div',{'id':'minDeposit'})\n",
    "emi  = soup.find_all('div',{'id':'roomType'})\n",
    "text = soup.find_all('span', {'class':'flex'})\n",
    "\n",
    "name = [_.text for _ in name]\n",
    "price= [_.find('span').text for _ in price]\n",
    "emi  = [_.text for _ in emi]\n",
    "place= [_.find('a', {'class':'text-default-color align-bottom underline hover:text-primary-color'}) for _ in text]\n",
    "place= [_['href'].split('/')[3] for _ in place if _ != None]\n",
    "\n",
    "house = [_.split('In') for _ in name]\n",
    "house = [_ for ]\n",
    "\n",
    "df = pd.DataFrame(data = {'House Title':name, 'Location':place,\n",
    "                          'EMI':emi, 'Price':price})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "e5333865",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = [_.split('In') for _ in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "06f058b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hal 2nd Stage,indiranagar  '"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "711eed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [_['href'].split('/')[3] for _ in temp if _ != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "72c9e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "9af61f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7371d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cd053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb8cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be0f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
