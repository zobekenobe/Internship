{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f14d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a57815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "url2 = 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc'\n",
    "url3 = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "url4 = 'https://meesho.com/bags-ladies/pl/p7vbp'\n",
    "url5a= 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "url5b = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "url5c= 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "url7 = 'https://coreyms.com/'\n",
    "url8 = 'https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIiLCJzaG93TWFwIjpmYWxzZX0seyJsYXQiOjEyLjkzMDc3MzUsImxvbiI6NzcuNTgzODMwMiwicGxhY2VJZCI6IkNoSUoyZGRsWjVnVnJqc1JoMUJPQWFmLW9ycyIsInBsYWNlTmFtZSI6IkpheWFuYWdhciIsInNob3dNYXAiOmZhbHNlfSx7ImxhdCI6MTIuOTc4MzY5MiwibG9uIjo3Ny42NDA4MzU2LCJwbGFjZUlkIjoiQ2hJSmtRTjNHS1FXcmpzUk5oQlFKcmhHRDdVIiwicGxhY2VOYW1lIjoiSW5kaXJhbmFnYXIiLCJzaG93TWFwIjpmYWxzZX1d'\n",
    "url10= 'https://www.bewakoof.com/women-tshirts?ga_q=tshirts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88df355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1(url):\n",
    "    text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    soup = bs(text)\n",
    "    headers = soup.find_all('head')\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc4e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2(url):\n",
    "    '''Since the top 100 are split over the two pages, two page links are created'''\n",
    "    page1 = requests.get(url)\n",
    "    page2 = requests.get(url + '&start=51&ref_=adv_nxt')\n",
    "    movie_list = []\n",
    "    for _ in [page1, page2]:\n",
    "        soup = bs(_.content)\n",
    "        text = soup.find_all('h3', {'class':'lister-item-header'})\n",
    "        movie_list += [_.text.split('\\n')[1:4] for _ in text]\n",
    "    df = pd.DataFrame(movie_list, columns = ['Rank', 'Movie Name', 'Year'])\n",
    "    df.set_index('Rank', inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3128bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3(url):\n",
    "    '''\n",
    "    Since the imdb site list the top 250 movies, the list is truncated to \n",
    "    the top 100 as required\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    text = soup.find_all('td', {'class':'titleColumn'})\n",
    "    rate = soup.find_all('td', {'class':'ratingColumn imdbRating'})\n",
    "    names  = [_.text.split('\\n')[1:4] for _ in text][0:100] \n",
    "    rating = [_.text.split('\\n')[1] for _ in rate][0:100]\n",
    "\n",
    "    df = pd.DataFrame(names, columns = ['Rank', 'Movie Name', 'Year'])\n",
    "    df.set_index('Rank', inplace = True)\n",
    "    df['rating'] = rating\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d88793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question4(url):\n",
    "    page = requests.get(url)\n",
    "    text = soup(page.content)\n",
    "    name = soup.find_all('p', {'class':'Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS'})\n",
    "    price= soup.find_all('h5',{'class':'Text__StyledText-sc-oo0kvp-0 hiHdyy'})\n",
    "    disc = soup.find_all('span', {'class' : 'Text__StyledText-sc-oo0kvp-0 lnonyH'})\n",
    "    name = [_.text for _ in name]\n",
    "    price= [_.text for _ in price]\n",
    "    disc = [_.text for _ in disc]\n",
    "    # to accomodate for cases with no discount\n",
    "    p = re.compile('â‚¹0')\n",
    "    i = next(i for i in range(len(price)) if p.findall(price[i]))\n",
    "    disc.insert(i, '0% off')\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Price':price, 'Discount':disc})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65f564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5a(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    team = soup.find_all('span', {'class':'u-hide-phablet'})\n",
    "    details = soup.find_all('td', {'class':'table-body__cell u-center-text'})\n",
    "    rating  = soup.find_all('td', {'class':'table-body__cell u-text-right rating'})\n",
    "\n",
    "    team = [_.text for _ in team][:10]\n",
    "    details = [_.text for _ in details]\n",
    "    rating  = [_.text for _ in rating]\n",
    "\n",
    "    match = [soup.find('td', {'class':'rankings-block__banner--matches'}).text]+details[0:18:2]\n",
    "    point = [soup.find('td', {'class':'rankings-block__banner--points'}).text] +details[1:18:2]\n",
    "    rating= [soup.find('td', {'class':'rankings-block__banner--rating u-text-right'}).text.split('\\n')[1].strip()] + rating[:9]\n",
    "    df = pd.DataFrame(data = {'Team':team, 'Matches':match, 'Points':point, 'Rating':rating}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d061bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5b(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b505962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5c(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e263211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6a(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    team = soup.find_all('span', {'class':'u-hide-phablet'})\n",
    "    details = soup.find_all('td', {'class':'table-body__cell u-center-text'})\n",
    "    rating  = soup.find_all('td', {'class':'table-body__cell u-text-right rating'})\n",
    "\n",
    "    team = [_.text for _ in team][:10]\n",
    "    details = [_.text for _ in details]\n",
    "    rating  = [_.text for _ in rating]\n",
    "\n",
    "    match = [soup.find('td', {'class':'rankings-block__banner--matches'}).text]+details[0:18:2]\n",
    "    point = [soup.find('td', {'class':'rankings-block__banner--points'}).text] +details[1:18:2]\n",
    "    rating= [soup.find('td', {'class':'rankings-block__banner--rating u-text-right'}).text.split('\\n')[1].strip()] + rating[:9]\n",
    "    df = pd.DataFrame(data = {'Team':team, 'Matches':match, 'Points':point, 'Rating':rating}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2fde83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6b(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce68325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6c(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('td',{'class':'table-body__cell rankings-table__name name'})\n",
    "    team = soup.find_all('span',{'class':'table-body__logo-text'})\n",
    "    rate = soup.find_all('td',{'class':'table-body__cell rating'})\n",
    "\n",
    "    name = soup.find('div', {'class':'rankings-block__banner--name-large'}).text.split('\\n') + [_.text.split('\\n')[1] for _ in name][:9]\n",
    "    team = [soup.find('div',{'class':'rankings-block__banner--nationality'}).text.split('\\n')[2]]+ [_.text for _ in team][:9]\n",
    "    rate= [soup.find('div',{'class':'rankings-block__banner--rating'}).text]+[_.text for _ in rate][:9]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Team':team, 'Rating':rate}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45464ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question7(url):\n",
    "    page= requests.get(url)\n",
    "    soup= bs(page.content)\n",
    "    title = soup.find_all('a', {'class':'entry-title-link'})\n",
    "    time  = soup.find_all('time', {'class':'entry-time'})\n",
    "    content = soup.find_all('div',{'class':'entry-content'})\n",
    "    link = soup.find_all('iframe', {'class':'youtube-player'})\n",
    "\n",
    "    title   = [_.text for _ in title]\n",
    "    time    = [_.text for _ in time]\n",
    "    content = [_.text.replace('\\n','').strip() for _ in content]\n",
    "    link    = [_['src'] for _ in link]\n",
    "    link.insert(4, 'No Link')\n",
    "    df = pd.DataFrame(data={'Title':title,'Date':time,'Content':content,'Youtube Link':link}, index = range(1,11))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bfc1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question8(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    name = soup.find_all('span',{'class':'overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full'})\n",
    "    price= soup.find_all('div',{'id':'minDeposit'})\n",
    "    emi  = soup.find_all('div',{'id':'roomType'})\n",
    "    text = soup.find_all('span', {'class':'flex'})\n",
    "\n",
    "    name = [_.text for _ in name]\n",
    "    price= [_.find('span').text for _ in price]\n",
    "    emi  = [_.text for _ in emi]\n",
    "    place= [_.find('a', {'class':'text-default-color align-bottom underline hover:text-primary-color'}) for _ in text]\n",
    "    place= [_['href'].split('/')[3] for _ in place if _ != None]\n",
    "\n",
    "    df = pd.DataFrame(data = {'House Title':name, 'Location':place,\n",
    "                              'EMI':emi, 'Price':price})\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c25bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question9(url):\n",
    "    '''\n",
    "    Question 9 couldn't be attempted because my IP address blocked since I'm\n",
    "    not in their service area. I have attached a screenshot of the same along with \n",
    "    the link the submission message\n",
    "    I can't install an VPN or proxy browser because this is a work laptop\n",
    "    and I wouldn't be allowed to install one.\n",
    "    Thank you\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133c4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question10(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    product = soup.find_all('div', {'class':'productCardDetail'})\n",
    "    img     = soup.find_all('img', {'class':'productImgTag'})\n",
    "    name  = [_.find('h3').text for _ in product][0:10]\n",
    "    price = [_.find('span').text for _ in product][0:10]\n",
    "    imgurl= [_['src'] for _ in img][0:10]\n",
    "    df = pd.DataFrame(data = {'Name':name, 'Price':price, 'Img URL':imgurl}, index = range(1, 11))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3d393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7dac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5a62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
